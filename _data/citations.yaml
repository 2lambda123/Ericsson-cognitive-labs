# DO NOT EDIT, GENERATED AUTOMATICALLY

- id: doi:10.48550/arXiv.2311.08118
  title: Evaluating Neighbor Explainability for Graph Neural Networks
  authors:
  - Oscar Llorente Gonzalez
  - Rana Fawzy
  - Jared keown
  - Michal Horemuz
  - "P\xE9ter Vaderna"
  - "S\xE1ndor Laki"
  - "Roland Kotrocz\xF3"
  - Rita Csoma
  - "J\xE1nos M\xE1rk Szalai-Gindl"
  publisher: arXiv
  date: '2023-11-14'
  link: https://doi.org/10.48550/arxiv.2311.08118
  type: paper
  image: images/light.jpg
  description: Explainability in Graph Neural Networks (GNNs) is a new field growing
    in the last few years. In this publication we address the problem of determining
    how important is each neighbor for the GNN when classifying a node and how to
    measure the performance for this specific task. To do this, various known explainability
    methods are reformulated to get the neighbor importance and four new metrics are
    presented. Our results show that there is almost no difference between the explanations
    provided by gradient-based techniques in the GNN domain. In addition, many explainability
    techniques failed to identify important neighbors when GNNs without self-loops
    are used.
  tags:
  - GAI Lab
  - Ericsson GAIA
  - Ericsson Research
  buttons:
  - type: paper
    text: Manuscript
    link: https://arxiv.org/abs/2311.08118
  - type: github
    text: Source Code
    link: EricssonResearch/gnn-neighbors-xai
  plugin: sources.py
  file: sources.yaml
- id: doi:10.48550/arXiv.2310.19573
  title: Model Uncertainty based Active Learning on Tabular Data using Boosted Trees
  authors:
  - Sharath M Shankaranarayana
  publisher: arXiv
  date: '2023-10-30'
  link: https://doi.org/10.48550/arxiv.2310.19573
  type: paper
  image: images/night.jpg
  description: Supervised machine learning relies on the availability of good labelled
    data for model training. Labelled data is acquired by human annotation, which
    is a cumbersome and costly process, often requiring subject matter experts. Active
    learning is a sub-field of machine learning which helps in obtaining the labelled
    data efficiently by selecting the most valuable data instances for model training
    and querying the labels only for those instances from the human annotator. Recently,
    a lot of research has been done in the field of active learning, especially for
    deep neural network based models. Although deep learning shines when dealing with
    image\textual\multimodal data, gradient boosting methods...
  buttons:
  - type: paper
    text: Manuscript
    link: https://arxiv.org/abs/2310.19573
  plugin: sources.py
  file: sources.yaml
- id: doi:10.48550/arXiv.2309.12913
  title: 'A matter of attitude: Focusing on positive and active gradients to boost
    saliency maps'
  authors:
  - Oscar Llorente Gonzalez
  - Jaime Boal
  - "Eugenio F. S\xE1nchez-\xDAbeda"
  publisher: arXiv
  date: '2023-09-22'
  link: https://doi.org/10.48550/arxiv.2309.12913
  type: paper
  image: images/space.jpg
  description: ESaliency maps have become one of the most widely used interpretability
    techniques for convolutional neural networks (CNN) due to their simplicity and
    the quality of the insights they provide. However, there are still some doubts
    about whether these insights are a trustworthy representation of what CNNs use
    to come up with their predictions. This paper explores how rescuing the sign of
    the gradients from the saliency map can lead to a deeper understanding of multi-class
    classification problems. Using both pretrained and trained from scratch CNNs we
    unveil that considering the sign and the effect not only of the correct class,
    but also the influence of the other classes, allows to better identify the pixels
    of the image that the network is really focusing on. Furthermore, how occluding
    or altering those pixels is expected to affect the outcome also becomes clearer.
  tags:
  - GAI Lab
  - Comillas Pontifical University (ICAI)
  buttons:
  - type: paper
    text: Manuscript
    link: https://arxiv.org/abs/2309.12913
  - type: github
    text: Source Code
    link: osllogon/positive_active_saliency_maps
  plugin: sources.py
  file: sources.yaml
